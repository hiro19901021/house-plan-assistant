import streamlit as st, backend as be, textwrap
# ---------- Overlay ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ----------
if "plans" not in st.session_state:
    st.session_state["plans"] = None
if "overlay_url" not in st.session_state:
    st.session_state["overlay_url"] = None
import streamlit.components.v1 as components
import uuid
from slugify import slugify

# --- Chat ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’åˆæœŸåŒ– ---
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []   # ç©ºãƒªã‚¹ãƒˆ

# --- ãƒ—ãƒ©ãƒ³å›ºå®šç”¨ ---
if "proposal_text" not in st.session_state:
    st.session_state["proposal_text"] = None


openai_key = st.secrets["OPENAI_API_KEY"]
be.openai.api_key = openai_key
sb = be.get_sb(st)

# ---------- ãƒšãƒ¼ã‚¸è¨­å®š ----------
st.set_page_config("HousePlan Assistant", layout="wide")
st.markdown("""
<style>
body{font-family: "Helvetica Neue", Arial; color:#222}
.sidebar-content{width:260px}
#MainMenu,footer,header{visibility:hidden}
</style>""", unsafe_allow_html=True)

# ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ----------
st.sidebar.header("PDF Upload")
pdfs = st.sidebar.file_uploader(
    "è¤‡æ•°é¸æŠå¯", type="pdf", accept_multiple_files=True)

if st.sidebar.button("Register PDFs") and pdfs:
    for pdf in pdfs:
        # ---------- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç† ----------
        safe_name = slugify(pdf.name, lowercase=False)
        path = f"{uuid.uuid4()}/{safe_name}"
        st.sidebar.info("Uploadingâ€¦")

        try:
            sb.storage.from_("floorplans").upload(
                path,
                pdf.getvalue(),
                {"content-type": "application/pdf"}
            )

            # ---- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã—ã¦ DB ã¸ä¿å­˜ ----
            # ---- ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² â†’ ãã‚Œãã‚ŒåŸ‹ã‚è¾¼ã¿ä¿å­˜ ----
            full_txt = be.pdf_to_text(pdf.getvalue())
            for chunk in be.chunk_text(full_txt):
                emb = be.embed(chunk)
            sb.table("floorplans").insert(
                {"filename": pdf.name,
                 "path": path,
                 "embedding": emb}
            ).execute()

            st.sidebar.success(f"âœ“ {pdf.name} uploaded")
        except Exception as e:
            st.sidebar.error(f"UPLOAD NG: {e}")
            st.stop()
        # ---------- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã“ã“ã¾ã§ ----------
# ---------- ãƒ—ãƒ©ãƒ³ç”Ÿæˆé–¢æ•° ----------
def generate_plan(request_row, plans):
    fam, rooms, area, bud, pref = (
        request_row["family_size"],
        request_row["rooms"],
        request_row["area_sqm"],
        request_row["budget_million_jpy"],
        request_row["preferences"],
    )
    ctx = "\n".join(p["filename"] for p in plans)
    prompt = f"""ã‚ãªãŸã¯ãƒã‚¦ã‚¹ãƒ¡ãƒ¼ã‚«ãƒ¼ã®è¨­è¨ˆå£«ã§ã™ã€‚
è¦æœ›: å®¶æ—{fam}äºº, {rooms}éƒ¨å±‹, {area}ã¡, äºˆç®—{bud}ä¸‡å††
ã“ã ã‚ã‚Š: {pref}
å‚è€ƒå›³é¢: {ctx}
æ—¥æœ¬èªã§æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’3æ¡ˆææ¡ˆã—ã¦ãã ã•ã„ã€‚"""
    rsp = be.openai.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"user","content":prompt}]
    )
    return rsp.choices[0].message.content

# ---------- è¦æœ›ãƒ•ã‚©ãƒ¼ãƒ  ----------
st.title("House-Plan Assistant")
with st.form("request"):
    col1, col2 = st.columns(2)
    fam   = col1.number_input("å®¶æ—äººæ•°", min_value=1, value=3)
    rooms = col1.number_input("å¸Œæœ›éƒ¨å±‹æ•°", min_value=1, value=3)
    area  = col1.number_input("å»¶åºŠé¢ç© (ã¡)", value=100)
    bud   = col2.number_input("äºˆç®— (ä¸‡å††)", value=3000)
    pref  = col2.text_area("ã“ã ã‚ã‚Š", "")
    submitted = st.form_submit_button("ãƒ—ãƒ©ãƒ³æç¤º")

if submitted:
    req = sb.table("customer_requests").insert(
        {"family_size": fam, "rooms": rooms,
         "area_sqm": area, "budget_million_jpy": bud,
         "preferences": pref}).execute().data[0]

    query = be.embed(f"{fam}äºº {rooms}éƒ¨å±‹ {area}ã¡ äºˆç®—{bud}ä¸‡å†† {pref}")
    plans = sb.rpc("match_plans", {"query": query, "top_n": 3}).execute().data
    st.session_state["plans"] = plans
    st.session_state["proposal_text"] = generate_plan(req, plans)
    st.experimental_rerun()     # ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡å¾Œã«ç”»é¢ã‚’ãƒªãƒ­ãƒ¼ãƒ‰


# ---------- ã“ã“ã‹ã‚‰ç½®ãæ›ãˆ ----------
plans = st.session_state["plans"]          # 1) ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å–ã‚Šå‡ºã™
if plans:
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
        st.subheader("é¡ä¼¼å›³é¢")  # ğŸ‘ˆ ã“ã“ã‚’ä¸Šã«ç§»å‹•
        for p in plans:
            url = sb.storage.from_("floorplans").create_signed_url(
                p["path"], 3600
            ).get("signedURL")

            # 2) ã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸ PDF ã® URL ã‚’ session_state ã«ä¿å­˜
            if st.button(p["filename"], key=f"btn_{p['id']}"):
                st.session_state["overlay_url"] = url

        st.subheader("ææ¡ˆãƒ—ãƒ©ãƒ³")
        st.markdown(st.session_state["proposal_text"])
# ---------- ãƒãƒ£ãƒƒãƒˆæ¬„ã“ã“ã‹ã‚‰ ----------  â˜…è¿½åŠ é–‹å§‹

# ---------- ãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤ºï¼ˆStreamlit æ¨™æº–ï¼‰ ----------
if st.session_state.get("overlay_url"):
    with st.modal("å›³é¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        st.components.v1.iframe(
            st.session_state["overlay_url"],
            height=600, width=800
        )
    # Ã—ã§é–‰ã˜ãŸã‚‰ãƒ•ãƒ©ã‚°ã‚’æ¶ˆã™
    st.session_state["overlay_url"] = None

st.divider()
st.subheader("è¿½åŠ è³ªå•ãƒ»ä¿®æ­£è¦æœ›ãƒãƒ£ãƒƒãƒˆ")

# â‘  ã“ã‚Œã¾ã§ã®ã‚„ã‚Šå–ã‚Šã‚’è¡¨ç¤º
for m in st.session_state["chat_history"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# â‘¡ å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹
if user_msg := st.chat_input("ã“ã“ã«è³ªå•ã‚„ä¿®æ­£è¦æœ›ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„â€¦"):
    # â‘¡-1 ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state["chat_history"].append({"role": "user", "content": user_msg})

    # â‘¡-2 LLM ã¸é€ä¿¡
    system_prompt = f"""
    ã‚ãªãŸã¯ãƒã‚¦ã‚¹ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å–¶æ¥­æ‹…å½“ã§ã™ã€‚
    ä»¥ä¸‹ã®ãƒ—ãƒ©ãƒ³æ¦‚è¦ã‚’å‰æã«ã€ãŠå®¢æ§˜ã®è¿½åŠ è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

    --- ãƒ—ãƒ©ãƒ³æ¦‚è¦ ---
    {st.session_state['proposal_text']}
    ------------------
    """

        reply = be.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=(
                [{"role": "system", "content": system_prompt}]
                + st.session_state["chat_history"]
            )
        ).choices[0].message.content

    # â‘¡-3 ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç™ºè¨€ã‚’å±¥æ­´ã¸
    st.session_state["chat_history"].append({"role": "assistant", "content": reply})

    st.experimental_rerun()   # ç”»é¢ã‚’å³ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
# ---------- ãƒãƒ£ãƒƒãƒˆæ¬„ã“ã“ã¾ã§ ----------  â˜…è¿½åŠ çµ‚äº†