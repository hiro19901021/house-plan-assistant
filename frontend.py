# ===== å…±é€šãƒ˜ãƒ«ãƒ‘ãƒ¼ =====
import streamlit as st
def show_pdf_modal(url: str):
    """
    Streamlit â‰¥1.29 ãªã‚‰ st.modal ã‚’ä½¿ã†ã€‚
    ãã‚Œæœªæº€ã€ã¾ãŸã¯ãƒã‚¹ãƒˆåˆ¶é™ã§ AttributeError ãŒå‡ºã‚‹ç’°å¢ƒã§ã¯
    ç°¡æ˜“ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã«è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ã€‚
    """
    def _body():
        st.markdown(
            f"<iframe src='{url}' width='100%' height='650' style='border:none'></iframe>",
            unsafe_allow_html=True,
        )

    # st.modal ãŒä½¿ãˆã‚‹ã‹åˆ¤å®š
    if hasattr(st, "modal"):
        try:
            with st.modal("å›³é¢ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", key="pdf_modal"):
                _body()
                if st.button("é–‰ã˜ã‚‹", key="close_modal_btn"):
                    st.session_state.pop("pdf_modal_url", None)
                    st.rerun()
        except AttributeError:
            # ã¾ã‚Œã«ãƒã‚¹ãƒˆåˆ¶é™ã§ AttributeError ãŒå‡ºã‚‹å ´åˆ
            st.warning("âš ï¸ è¡¨ç¤ºç’°å¢ƒã®éƒ½åˆã§ç°¡æ˜“ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ãªã‚Šã¾ã™")
            _body()
    else:
        st.warning("âš ï¸ Streamlit ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒå¤ã„ãŸã‚ç°¡æ˜“ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ãªã‚Šã¾ã™")
        _body()

import streamlit as st, backend as be, textwrap
# ---------- Overlay ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ----------
if "plans" not in st.session_state or not isinstance(st.session_state["plans"], list):
    st.session_state["plans"] = []     # ç©ºãƒªã‚¹ãƒˆã‚’ä¿è¨¼
if "chat_history" not in st.session_state:      # â˜…è¿½åŠ 
    st.session_state["chat_history"] = []       # â˜…è¿½åŠ 
import streamlit.components.v1 as components
import uuid
from slugify import slugify

openai_key = st.secrets["OPENAI_API_KEY"]
be.openai.api_key = openai_key
sb = be.get_sb(st)

# ---------- ãƒšãƒ¼ã‚¸è¨­å®š ----------
st.set_page_config("HousePlan Assistant", layout="wide")
st.markdown("""
<style>
body{font-family: "Helvetica Neue", Arial; color:#222}
.sidebar-content{width:260px}
#MainMenu,footer,header{visibility:hidden}
</style>""", unsafe_allow_html=True)

# ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ----------
st.sidebar.header("PDF Upload")
pdfs = st.sidebar.file_uploader(
    "è¤‡æ•°é¸æŠå¯", type="pdf", accept_multiple_files=True)

if st.sidebar.button("Register PDFs") and pdfs:
    for pdf in pdfs:
        # ---------- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç† ----------
        safe_name = slugify(pdf.name, lowercase=False)
        path = f"{uuid.uuid4()}/{safe_name}"
        st.sidebar.info("Uploadingâ€¦")

        try:
            sb.storage.from_("floorplans").upload(
                path,
                pdf.getvalue(),
                {"content-type": "application/pdf"}
            )

            # ---- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—ã—ã¦ DB ã¸ä¿å­˜ ----
                        # ---- ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰² â†’ ãã‚Œãã‚ŒåŸ‹ã‚è¾¼ã¿ä¿å­˜ ----
            full_txt = be.pdf_to_text(pdf.getvalue())
            for chunk in be.chunk_text(full_txt):
                emb = be.embed(chunk)
                sb.table("floorplans").insert(
                    {"filename": pdf.name,
                     "path": path,
                     "embedding": emb}
                ).execute()


            st.sidebar.success(f"âœ“ {pdf.name} uploaded")
        except Exception as e:
            st.sidebar.error(f"UPLOAD NG: {e}")
            st.stop()
        # ---------- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã“ã“ã¾ã§ ----------

# ---------- è¦æœ›ãƒ•ã‚©ãƒ¼ãƒ  ----------
st.title("House-Plan Assistant")
with st.form("request"):
    col1, col2 = st.columns(2)
    fam   = col1.number_input("å®¶æ—äººæ•°", min_value=1, value=3)
    rooms = col1.number_input("å¸Œæœ›éƒ¨å±‹æ•°", min_value=1, value=3)
    area  = col1.number_input("å»¶åºŠé¢ç© (ã¡)", value=100)
    bud   = col2.number_input("äºˆç®— (ä¸‡å††)", value=3000)
    pref  = col2.text_area("ã“ã ã‚ã‚Š", "")
    submitted = st.form_submit_button("ãƒ—ãƒ©ãƒ³æç¤º")

if submitted:
    req = sb.table("customer_requests").insert(
        {"family_size": fam, "rooms": rooms,
         "area_sqm": area, "budget_million_jpy": bud,
         "preferences": pref}).execute().data[0]
    query = be.embed(
        f"{fam}äºº {rooms}éƒ¨å±‹ {area}ã¡ äºˆç®—{bud}ä¸‡å†† {pref}")
    plans = sb.rpc("match_plans",
                   {"query": query, "top_n": 3}).execute().data
    st.session_state["plans"] = plans

# ---------- é¡ä¼¼å›³é¢ï¼ˆé‡è¤‡é™¤å»â†’ä¸€è¦§â†’ãƒ¢ãƒ¼ãƒ€ãƒ«ï¼‰ ----------
# plans ã‚’ç©ºãƒªã‚¹ãƒˆã§åˆæœŸåŒ–ã—ã¦ãŠãã¨ TypeError ã‚’æ ¹æœ¬å›é¿
plans = st.session_state.get("plans", [])
if not isinstance(plans, list):
    plans = []                  # å®‰å…¨å¼

if plans:
    # â¶ é‡è¤‡é™¤å»: ç½²åãƒˆãƒ¼ã‚¯ãƒ³ã‚’é™¤ã„ãŸ path ã§è¾æ›¸åŒ–
    uniq = {}
    for p in plans:
        key_path = p["path"].split("?")[0]
        uniq[key_path] = p      # å¾Œå‹ã¡ã§ã‚‚å†…å®¹ã¯åŒã˜
    plans = list(uniq.values())

    st.subheader("é¡ä¼¼å›³é¢")

    # â· ãƒœã‚¿ãƒ³åˆ—
    for p in plans:
        signed = sb.storage.from_("floorplans").create_signed_url(
            p["path"], 3600
        ).get("signedURL")

        btn_key = f"similar_{hash(p['path'].split('?')[0])}"
        if st.button(p["filename"], key=btn_key):
            # æ—¢ã«ãƒ¢ãƒ¼ãƒ€ãƒ«ãŒé–‹ã„ã¦ã„ã‚Œã° URL ã‚’æ›´æ–°
            st.session_state["pdf_modal_url"] = signed

# â¸ ãƒ¢ãƒ¼ãƒ€ãƒ«å‘¼ã³å‡ºã—ï¼ˆå¿…ãš 1 ã‹æ‰€ï¼‰
if "pdf_modal_url" in st.session_state:
    show_pdf_modal(st.session_state["pdf_modal_url"])
# ---------- é¡ä¼¼å›³é¢ãƒ–ãƒ­ãƒƒã‚¯ã“ã“ã¾ã§ ----------


    st.subheader("ææ¡ˆãƒ—ãƒ©ãƒ³")
    ctx = "\n".join(f"{p['filename']}" for p in plans)
    prompt = f"""ã‚ãªãŸã¯ãƒã‚¦ã‚¹ãƒ¡ãƒ¼ã‚«ãƒ¼ã®è¨­è¨ˆå£«ã§ã™ã€‚
è¦æœ›: å®¶æ—{fam}äºº, {rooms}éƒ¨å±‹, {area}ã¡, äºˆç®—{bud}ä¸‡å††
ã“ã ã‚ã‚Š: {pref}
å‚è€ƒå›³é¢: {ctx}
æ—¥æœ¬èªã§æœ€é©ãªãƒ—ãƒ©ãƒ³ã‚’3æ¡ˆææ¡ˆã—ã¦ãã ã•ã„ã€‚"""
    with st.spinner("ææ¡ˆãƒ—ãƒ©ãƒ³ã‚’æ¤œè¨ä¸­ã§ã™â€¦"):
        ans = be.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"user","content":prompt}]
        ).choices[0].message.content
    st.write(ans)
    # ---------- ãƒãƒ£ãƒƒãƒˆæ¬„ã“ã“ã‹ã‚‰ ----------  â˜…è¿½åŠ é–‹å§‹
st.divider()
st.subheader("ğŸ’¬ è¿½åŠ è³ªå•ãƒ»ä¿®æ­£è¦æœ›ãƒãƒ£ãƒƒãƒˆ")

# â‘  ã“ã‚Œã¾ã§ã®ã‚„ã‚Šå–ã‚Šã‚’è¡¨ç¤º
for m in st.session_state["chat_history"]:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# â‘¡ å…¥åŠ›ãƒœãƒƒã‚¯ã‚¹
if user_msg := st.chat_input("ã“ã“ã«è³ªå•ã‚„ä¿®æ­£è¦æœ›ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„â€¦"):
    # â‘¡-1 ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state["chat_history"].append({"role": "user", "content": user_msg})

    # â‘¡-2 LLM ã¸é€ä¿¡
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­â€¦"):
        system_prompt = "ã“ã‚Œã¾ã§ã®ãƒ—ãƒ©ãƒ³ææ¡ˆã¨ä»¥ä¸‹ã®è¿½åŠ è¦æœ›ã‚’è¸ã¾ãˆã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        reply = be.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=(
                [{"role": "system", "content": system_prompt}]
                + st.session_state["chat_history"]
            )
        ).choices[0].message.content

    # â‘¡-3 ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆç™ºè¨€ã‚’å±¥æ­´ã¸
    st.session_state["chat_history"].append({"role": "assistant", "content": reply})

    st.experimental_rerun()   # ç”»é¢ã‚’å³ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
# ---------- ãƒãƒ£ãƒƒãƒˆæ¬„ã“ã“ã¾ã§ ----------  â˜…è¿½åŠ çµ‚äº†
